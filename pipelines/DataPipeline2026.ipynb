{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe847e82",
   "metadata": {},
   "source": [
    "# Data Pipeline 2026\n",
    "This Jupyter notebook contains the pipelines to run in 2026 to fetch 2025 data and update the Water Rights Visualizer tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d79a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/nmw-pipelines/lib/python3.10/site-packages/geemap/conversion.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os.path import join\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from pipelines.gee.gee_aws_pipeline import GEEAWSDataPipeline\n",
    "from pipelines.prism.prism_aws_pipeline import PrismAWSDataPipeline\n",
    "from pipelines.gridmet.gridmet_pipeline import GridMETPipeline\n",
    "\n",
    "# Specify the path to the Google Drive client secret and key files\n",
    "# To generate, follow these instructions: https://docs.iterative.ai/PyDrive2/quickstart/\n",
    "current_dir = os.path.dirname(os.getcwd())\n",
    "secret_path = join(current_dir, \"pipelines/client_secret.json\")\n",
    "key_path = join(current_dir, \"pipelines/google_drive_key.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Google Earth Engine project ID is shown in Google Cloud Platform (https://console.cloud.google.com/) when selecting the project name.\n",
    "# This project must have the Google Earth Engine API enabled to work correctly\n",
    "GEE_PROJECT_ID = \"zippy-pad-465521-e2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97175540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "ee.Authenticate(auth_mode=\"notebook\")\n",
    "ee.Initialize(project=GEE_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbf127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline, configured for the OpenET ensemble product (ET, ET_MIN, ET_MAX)\n",
    "pipeline = GEEAWSDataPipeline(\n",
    "    bands=[\"et_ensemble_mad\", \"et_ensemble_mad_min\", \"et_ensemble_mad_max\"],\n",
    "    product=\"OpenET/ENSEMBLE/CONUS/GRIDMET/MONTHLY/v2_0\",\n",
    "    product_prefix=\"OPENET_ENSEMBLE\",\n",
    "    aws_bucket=\"ose-dev-inputs\",\n",
    "    aws_region=\"us-west-2\",\n",
    "    aws_profile=\"ose-nmw\",\n",
    "    gdrive_folder=\"OPENET_EXPORTS\",\n",
    "    temp_local_folder=\"temp_data\",\n",
    "    project=GEE_PROJECT_ID,\n",
    "    gdrive_client_secrets_filename=secret_path,\n",
    "    gdrive_key_filename=key_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate export of ET, ET_MIN, and ET_MAX tiles for the full year of 2025\n",
    "pipeline.generate_tiles_for_date_range(\"2025-01-01\", \"2026-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa8862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only run this after all tiles have been generated. This may take a couple hours to days to complete.\n",
    "# You can check the status of the jobs in Google Cloud Console here: \n",
    "# https://console.cloud.google.com/earth-engine/tasks?project=zippy-pad-465521-e2\n",
    "# While waiting, you can run the next non-Google Earth Engine pipelines\n",
    "pipeline.transfer_gdrive_to_aws(delete_from_local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e501d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline directly downloads the PRISM data from the PRISM website (not Google Earth Engine)\n",
    "prism_pipeline = PrismAWSDataPipeline(\n",
    "    aws_bucket=\"ose-dev-inputs\",\n",
    "    aws_region=\"us-west-2\",\n",
    "    aws_profile=\"ose-nmw\",\n",
    "    raw_dir=\"prism_data\",\n",
    "    monthly_dir=\"prism_data_monthly\",\n",
    "    output_dir=\"prism_tiles\",\n",
    "    allow_provisional=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d837fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch, format, and process the PRISM data for 2025 and store locally (should only take a few minutes)\n",
    "prism_pipeline.process_year(2025, upload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47339e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the local PRISM data to AWS (might take a few hours depending on network speed)\n",
    "prism_pipeline.upload_local_folder_to_aws()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This pipeline directly downloads the GridMET data from the GridMET website (not Google Earth Engine)\n",
    "gridmet_climate_engine_pipeline = GridMETPipeline(\n",
    "    bands=[\"pet\"],\n",
    "    aws_profile=\"ose-nmw\",\n",
    "    aws_bucket=\"ose-dev-inputs\",\n",
    "    aws_region=\"us-west-2\",\n",
    ")\n",
    "gridmet_climate_engine_pipeline.fetch_year(2025)\n",
    "gridmet_climate_engine_pipeline.upload_to_aws(delete_on_success=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After all data has been uploaded to AWS (including Google Earth Engine ET data), run this to update the tool's manifest\n",
    "tracker = S3ManifestTracker(\n",
    "    config_path=\"../variables.yaml\",\n",
    "    bucket_name=\"ose-dev-inputs\",\n",
    "    output_path=\"S3_filenames_dynamic.csv\",\n",
    "    profile_name=\"ose-nmw\",\n",
    ")\n",
    "\n",
    "# This will replace the current manifest with the new data\n",
    "tracker.update_manifest(output_path=\"../water_rights_visualizer/S3_filenames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59183ce4",
   "metadata": {},
   "source": [
    "# Final Steps:\n",
    "After all above cells have been run and the manifest has been updated, the next step is to update the tool to use the new data.\n",
    "\n",
    "1. Go to variables.yaml and update the end dates of the following data product IDs to \"2026-01-01\":\n",
    "    - openet_ensemble_et\n",
    "    - openet_ensemble_et_min\n",
    "    - openet_ensemble_et_max\n",
    "    - idaho_epscor_gridmet_eto\n",
    "    - oregon_state_prism_ppt\n",
    "2. Go to client/src/utils/constants.tsx and update the DATA_END_YEAR variable to 2025\n",
    "3. Update the et_tool_data_docs.pdf to reflect the new data end date (and any new data caveats). This can be done by opening `water_rights_visualizer/et_tool_data_docs.docx` in Microsoft Word, updating, and saving as a PDF in the same directory.\n",
    "4. Commit changes to git, merge to main, and deploy to production.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmw-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
